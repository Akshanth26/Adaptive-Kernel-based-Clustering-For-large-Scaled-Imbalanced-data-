import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN
from sklearn.preprocessing import StandardScaler
from imblearn.over_sampling import SMOTE
from sklearn.model_selection import train_test_split
from scipy.stats import mode
from collections import Counter
from sklearn.metrics import confusion_matrix, silhouette_score
from scipy.cluster.hierarchy import dendrogram, linkage
from sklearn.decomposition import PCA

# ðŸ“Œ Load dataset
file_path = "UCI_Credit_Card.csv"
data = pd.read_csv(file_path)

# ðŸ“Œ Select features (removing ID column)
X = data.iloc[:, 1:-1]
y = data.iloc[:, -1]  # Target variable

# ðŸ“Œ Apply SMOTE to handle class imbalance
print("Class distribution before SMOTE:", Counter(y))
smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X, y)
print("Class distribution after SMOTE:", Counter(y_resampled))

# ðŸ“Œ Standardize features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_resampled)

# ðŸ“Œ Split dataset
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_resampled, test_size=0.2, random_state=42)

# ðŸ“Œ Function to compute cluster purity
def cluster_purity(true_labels, cluster_labels):
    cluster_df = pd.DataFrame({'true_label': true_labels, 'cluster': cluster_labels})
    majority_class_counts = cluster_df.groupby('cluster')['true_label'].apply(lambda x: mode(x, keepdims=True).mode[0])
    total_correct = sum(cluster_df.groupby('cluster')['true_label'].apply(lambda x: (x == mode(x, keepdims=True).mode[0]).sum()))
    return total_correct / len(true_labels)

# ðŸ“Œ K-Means Clustering
kmeans = KMeans(n_clusters=2, random_state=42, n_init=10)
kmeans_labels_train = kmeans.fit_predict(X_train)
kmeans_labels_test = kmeans.predict(X_test)
purity_kmeans = cluster_purity(y_test, kmeans_labels_test)
silhouette_kmeans = silhouette_score(X_test, kmeans_labels_test)

# ðŸ“Œ Agglomerative Clustering
agglo = AgglomerativeClustering(n_clusters=2)
agglo_labels_test = agglo.fit_predict(X_test)
purity_agglo = cluster_purity(y_test, agglo_labels_test)
silhouette_agglo = silhouette_score(X_test, agglo_labels_test)

# ðŸ“Œ DBSCAN Clustering
dbscan = DBSCAN(eps=0.5, min_samples=5)
dbscan_labels_test = dbscan.fit_predict(X_test)
purity_dbscan = cluster_purity(y_test, dbscan_labels_test)
silhouette_dbscan = silhouette_score(X_test, dbscan_labels_test) if len(set(dbscan_labels_test)) > 1 else -1

# ðŸ“Œ Training & Testing Accuracy
train_accuracy = cluster_purity(y_train, kmeans_labels_train)
test_accuracy = purity_kmeans
accuracy_gap = abs(train_accuracy - test_accuracy)

# ðŸ“Œ Confusion Matrix
conf_matrix = confusion_matrix(y_test, kmeans_labels_test)

# ðŸ“Œ Dendrogram for Agglomerative Clustering
plt.figure(figsize=(8, 5))
linked = linkage(X_test[:100], method='ward')  # Limiting to 100 points for readability
dendrogram(linked)
plt.title("Dendrogram for Agglomerative Clustering")
plt.xlabel("Data Points")
plt.ylabel("Distance")
plt.show()

# ðŸ“Œ PCA Landmark Graph
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_test)
plt.figure(figsize=(7, 5))
plt.scatter(X_pca[:, 0], X_pca[:, 1], c=kmeans_labels_test, cmap='viridis', alpha=0.6)
plt.colorbar()
plt.title("Landmark Graph using PCA")
plt.xlabel("PCA Component 1")
plt.ylabel("PCA Component 2")
plt.show()

# ðŸ“Œ Print Accuracies & Scores
print("\nðŸ”¹ Clustering Comparisons:")
print(f"K-Means Purity: {purity_kmeans:.4f}")
print(f"Agglomerative Clustering Purity: {purity_agglo:.4f}")
print(f"DBSCAN Purity: {purity_dbscan:.4f} (likely lowest due to noise)")
print(f"\nðŸ”¹ Silhouette Scores:")
print(f"K-Means: {silhouette_kmeans:.4f}")
print(f"Agglomerative Clustering: {silhouette_agglo:.4f}")
print(f"DBSCAN: {silhouette_dbscan:.4f}")

print(f"\nðŸ”¹ Training Accuracy: {train_accuracy:.4f}")
print(f"ðŸ”¹ Testing Accuracy: {test_accuracy:.4f}")
print(f"ðŸ”¹ Accuracy Gap (ACU Gap): {accuracy_gap:.4f}")

print("\nðŸ”¹ Confusion Matrix (K-Means):")
print(conf_matrix)
